{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3630eea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 18:45:16.264603: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-29 18:45:16.360439: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-29 18:45:16.362454: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 18:45:17.431230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "字符编码的策略:\n",
    "1.one-hot encoding\n",
    "2.Encode each word with a unique number\n",
    "3.Word embeddings\n",
    "\"\"\"\n",
    "# Word embeddings--trainable parameters\n",
    "# higher dimension -> fine-grained relationships \n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe01bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'README', 'imdb.vocab', 'train', 'imdbEr.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
    "                                  untar=True, cache_dir='.',\n",
    "                                  cache_subdir='')\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeba2d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos',\n",
       " 'urls_neg.txt',\n",
       " 'urls_unsup.txt',\n",
       " 'urls_pos.txt',\n",
       " 'unsupBow.feat',\n",
       " 'labeledBow.feat',\n",
       " 'unsup',\n",
       " 'neg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bada2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b84b3935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 18:45:53.715973: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 123\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='training', seed=seed)\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='validation', seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3355dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 18:45:56.396398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [20000]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-03-29 18:45:56.397480: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [20000]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 b\"Oh My God! Please, for the love of all that is holy, Do Not Watch This Movie! It it 82 minutes of my life I will never get back. Sure, I could have stopped watching half way through. But I thought it might get better. It Didn't. Anyone who actually enjoyed this movie is one seriously sick and twisted individual. No wonder us Australians/New Zealanders have a terrible reputation when it comes to making movies. Everything about this movie is horrible, from the acting to the editing. I don't even normally write reviews on here, but in this case I'll make an exception. I only wish someone had of warned me before I hired this catastrophe\"\n",
      "1 b'This movie is SOOOO funny!!! The acting is WONDERFUL, the Ramones are sexy, the jokes are subtle, and the plot is just what every high schooler dreams of doing to his/her school. I absolutely loved the soundtrack as well as the carefully placed cynicism. If you like monty python, You will love this film. This movie is a tad bit \"grease\"esk (without all the annoying songs). The songs that are sung are likable; you might even find yourself singing these songs once the movie is through. This musical ranks number two in musicals to me (second next to the blues brothers). But please, do not think of it as a musical per say; seeing as how the songs are so likable, it is hard to tell a carefully choreographed scene is taking place. I think of this movie as more of a comedy with undertones of romance. You will be reminded of what it was like to be a rebellious teenager; needless to say, you will be reminiscing of your old high school days after seeing this film. Highly recommended for both the family (since it is a very youthful but also for adults since there are many jokes that are funnier with age and experience.'\n",
      "0 b\"Alex D. Linz replaces Macaulay Culkin as the central figure in the third movie in the Home Alone empire. Four industrial spies acquire a missile guidance system computer chip and smuggle it through an airport inside a remote controlled toy car. Because of baggage confusion, grouchy Mrs. Hess (Marian Seldes) gets the car. She gives it to her neighbor, Alex (Linz), just before the spies turn up. The spies rent a house in order to burglarize each house in the neighborhood until they locate the car. Home alone with the chicken pox, Alex calls 911 each time he spots a theft in progress, but the spies always manage to elude the police while Alex is accused of making prank calls. The spies finally turn their attentions toward Alex, unaware that he has rigged devices to cleverly booby-trap his entire house. Home Alone 3 wasn't horrible, but probably shouldn't have been made, you can't just replace Macauley Culkin, Joe Pesci, or Daniel Stern. Home Alone 3 had some funny parts, but I don't like when characters are changed in a movie series, view at own risk.\"\n",
      "0 b\"There's a good movie lurking here, but this isn't it. The basic idea is good: to explore the moral issues that would face a group of young survivors of the apocalypse. But the logic is so muddled that it's impossible to get involved.<br /><br />For example, our four heroes are (understandably) paranoid about catching the mysterious airborne contagion that's wiped out virtually all of mankind. Yet they wear surgical masks some times, not others. Some times they're fanatical about wiping down with bleach any area touched by an infected person. Other times, they seem completely unconcerned.<br /><br />Worse, after apparently surviving some weeks or months in this new kill-or-be-killed world, these people constantly behave like total newbs. They don't bother accumulating proper equipment, or food. They're forever running out of fuel in the middle of nowhere. They don't take elementary precautions when meeting strangers. And after wading through the rotting corpses of the entire human race, they're as squeamish as sheltered debutantes. You have to constantly wonder how they could have survived this long... and even if they did, why anyone would want to make a movie about them.<br /><br />So when these dweebs stop to agonize over the moral dimensions of their actions, it's impossible to take their soul-searching seriously. Their actions would first have to make some kind of minimal sense.<br /><br />On top of all this, we must contend with the dubious acting abilities of Chris Pine. His portrayal of an arrogant young James T Kirk might have seemed shrewd, when viewed in isolation. But in Carriers he plays on exactly that same note: arrogant and boneheaded. It's impossible not to suspect that this constitutes his entire dramatic range.<br /><br />On the positive side, the film *looks* excellent. It's got an over-sharp, saturated look that really suits the southwestern US locale. But that can't save the truly feeble writing nor the paper-thin (and annoying) characters. Even if you're a fan of the end-of-the-world genre, you should save yourself the agony of watching Carriers.\"\n",
      "0 b'I saw this movie at an actual movie theater (probably the $2.00 one) with my cousin and uncle. We were around 11 and 12, I guess, and really into scary movies. I remember being so excited to see it because my cool uncle let us pick the movie (and we probably never got to do that again!) and sooo disappointed afterwards!! Just boring and not scary. The only redeeming thing I can remember was Corky Pigeon from Silver Spoons, and that wasn\\'t all that great, just someone I recognized. I\\'ve seen bad movies before and this one has always stuck out in my mind as the worst. This was from what I can recall, one of the most boring, non-scary, waste of our collective $6, and a waste of film. I have read some of the reviews that say it is worth a watch and I say, \"Too each his own\", but I wouldn\\'t even bother. Not even so bad it\\'s good.'\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(label_batch[i].numpy(), text_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ccce768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make sure I/O not become blocking:\n",
    "1.cache():This will ensure the dataset does not become a \n",
    "bottleneck while training your model.If your dataset is too \n",
    "large to fit into memory, you can also use this method to create \n",
    "a performant on-disk cache, which is more efficient to read than \n",
    "many small files.\n",
    "2.prefetch():overlaps data preprocessing and model execution while training.\n",
    "\"\"\"\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b52b0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0083099 ,  0.00552003, -0.03571228,  0.01776811, -0.01485022],\n",
       "       [ 0.01776758,  0.02911956, -0.04845239, -0.02687578, -0.00223989],\n",
       "       [ 0.02623161, -0.02557815, -0.04145522, -0.02449559,  0.04076444]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Embedding layer: map integer indices to dense vectors\n",
    "\"\"\"\n",
    "# embed 1000 word vocabulary into 5 dimensions\n",
    "# randomly initialized, during training gradually ajusted to your task\n",
    "embedding_layer = tf.keras.layers.Embedding(1000, 5)\n",
    "result = embedding_layer(tf.constant([1,2,3]))\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f3eae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batchsize, length, embedding_dimensionality\n",
    "result = embedding_layer(tf.constant([[0,1,2],[2,3,5]]))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48fa90f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:23:45.338580: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [20000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-03-29 19:23:45.339445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [20000]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"The original animated Dark Knight returns in this ace adventure movie that rivals Mask of Phantasm in its coolness. There's a lot of style and intelligence in Mystery of the Batwoman, so much more than Batman Forever or Batman and Robin.<br /><br />There's a new crime-fighter on the streets of Gotham. She dresses like a bat but she's not a grown-up Batgirl. And Batman is denying any affiliation with her. Meanwhile Bruce Wayne has to deal with the usual romances and detective work. But the Penguin, Bain and the local Mob makes things little more complicated.<br /><br />I didn't have high hopes for this 'un since being strongly let down but the weak Batman: Sub Zero (Robin isn't featured so much here!)but I was delighted with the imaginative and exciting set pieces, the clever plot and a cheeky sense of humor. This is definitely a movie no fan of Batman should be without. Keep your ears open for a really catchy song called 'Betcha Neva' which is featured prominently through-out.<br /><br />It's a shame the DVD isn't so great. Don't get me wrong there are some great features (the short 'Chase Me' is awesome) and a very cool Dolby 5.1 soundtrack but... the movie is presented in Pan and Scan. Batman: Mystery of the Batwoman was drawn and shot in 1.85:1 but this DVD is presented in 1.33:1 an in comparison to the widescreen clips shown on the features there IS picture cut off on both sides. I find this extremely annoying considering Mask of Phantasm was presented in anamorphic widescreen. Warner have had to re-release literally dozens of movies on DVD because people have complained about the lack of Original Aspect Ratio available on some titles. Why they chose to make that same mistake here again is beyond me.<br /><br />I would give this DVD 5/5 but the lack of OAR brings the overall score down to 4/5. It's a shame because widescreen would have completed a great DVD package.\"\n",
      "b'Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas\\' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother\\'s slow awakening to what\\'s happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they\\'d all be \"up\" for this movie.'\n",
      "b'I claim no matter how hard I seek I\\'ll never find a better movie version of \"Othello\". If you love Kenneth Branagh\\'s magnificent masterpieces \"Much ado about nothing\" (1993) and \"Hamlet\" (1996) as much as I do I\\'m dead certain you\\'ll also find Oliver Parker\\'s \"Othello\" irresistible. Laurence Fishburne has been in a various splendid roles during his career. He was quite terrific in \"Boys n the hood\" (1991) - I\\'ve always considered his amusing role of Furious Styles as his very greatest achievement. That was, of course, way before I saw this.<br /><br />He plays the part of Othello and he is probably in the most challenging role of his whole career but he does a brilliant, fantastic job. Ir\\xc3\\xa8ne Jacob is absolutely charming Desdemona and Kenneth Branagh is just simply phenomenal in a most fascinating role of the story\\'s crooked, manipulate villain Iago. Marvelous \"Othello\" is part of the absolute elite among Shakespeare\\'s ingenious works. It deals with his favorite topics: crookedness, envy, deceitfulness and jealousy. This movie adaptation is certainly one of the finest films I\\'ve seen that\\'s based on William Shakespeare\\'s plays.'\n",
      "b\"Some people say this is the best film that PRC ever released, I'm not too sure about that since I have a fond place in my heart for some of their mysteries. I will say that this is probably one of the most unique films they, or any other studio, major or minor, ever released.<br /><br />The plot is simple. The ghost of a wrongly executed ferryman has returned to the swamp to kill all those who lynched him as well as all of their off spring. Into this mix comes the granddaughter of one ghosts victims, the current ferryman. She takes over the ferry business as the ghost closes in on the man she loves.<br /><br />Shrouded in dense fog and set primarily on the single swamp set this is more musical poem than regular feature film.Listen to the rhythms of the dialog, especially in the early scenes, their is poetical cadence to them. Likewise there is a similar cadence to the camera work as it travels back and forth across the swamp as if crossing back and forth across the door way between life and death, innocence and guilt. The film reminds me of an opera or oratorio or musical object lesson more than a normal horror film. Its an amazing piece of film making that is probably unique in film history.<br /><br />This isn't to guild the Lilly. This is a low budget horror/mystery that tells you a neat little story that will keep you entertained. Its tale of love and revenge is what matters here, not the poetical film making and it holds you attention first and foremost (the technical aspects just being window dressing.) If there is any real flaw its the cheapness of the production. The fog does create a mood but it also hides the fact that this swamp is entirely on dry land. The constant back and forth across it is okay for a while but even after 58 minutes you do wish that we could see something else.<br /><br />Don't get me wrong I do like the film a great deal. Its a good little film that I some how wish was slightly less poverty stricken. Its definitely worth a look if you can come across it.\"\n",
      "b'A journey of discovery, this film follows the lives of one family living in a sleepy, island town in British Columbia. Languorous and dreamy, the inhabitants are satisfied to allow life to go on around them until a young, fresh-faced teacher, with new ideas arrives and brings with her life from the mainland. Slowly, their indolent state is awakened, the father (and principal of the local school) looks for excitement, the mother for stability, the oldest daughter for love, and the youngest for power. While not an incredible or ground-breaking piece of cinema, the movie is quietly enjoyable and good for a tired night when the wind is blowing. Unfortunately, I doubt anyone outside of Canada will find it easily accessible.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:23:47.636426: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [20000]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-03-29 19:23:47.637084: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [20000]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Text preprocessing\n",
    "\"\"\" \n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "vocab_size=10000\n",
    "sequence_length=100\n",
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to integers\n",
    "# Note that the layer uses the custom standardization defined above.\n",
    "# Set maximum_sequence length as all samples are not of the same length\n",
    "# ⭐⭐\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "# make a text-only dataset(without labels)\n",
    "text_ds = train_ds.map(lambda x, y : x)\n",
    "# call adapt to build the vocabulary\n",
    "vectorize_layer.adapt(text_ds)\n",
    "for text_batch in text_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(text_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e1b2ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:07:27.037311: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [20000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-03-29 19:07:27.038156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [20000]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:07:30.536882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [5000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-03-29 19:07:30.537764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [5000]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 173ms/step - loss: 0.6920 - accuracy: 0.5028 - val_loss: 0.6900 - val_accuracy: 0.4886\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 3s 143ms/step - loss: 0.6872 - accuracy: 0.5028 - val_loss: 0.6838 - val_accuracy: 0.4886\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 3s 142ms/step - loss: 0.6791 - accuracy: 0.5028 - val_loss: 0.6739 - val_accuracy: 0.4886\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 3s 147ms/step - loss: 0.6666 - accuracy: 0.5028 - val_loss: 0.6595 - val_accuracy: 0.4886\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 3s 151ms/step - loss: 0.6490 - accuracy: 0.5031 - val_loss: 0.6404 - val_accuracy: 0.4914\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 3s 140ms/step - loss: 0.6262 - accuracy: 0.5341 - val_loss: 0.6171 - val_accuracy: 0.5486\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 3s 153ms/step - loss: 0.5988 - accuracy: 0.6029 - val_loss: 0.5908 - val_accuracy: 0.6140\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 3s 145ms/step - loss: 0.5682 - accuracy: 0.6738 - val_loss: 0.5632 - val_accuracy: 0.6638\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 3s 153ms/step - loss: 0.5361 - accuracy: 0.7230 - val_loss: 0.5353 - val_accuracy: 0.6986\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.5033 - accuracy: 0.7578 - val_loss: 0.5086 - val_accuracy: 0.7294\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 3s 143ms/step - loss: 0.4723 - accuracy: 0.7811 - val_loss: 0.4850 - val_accuracy: 0.7460\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 3s 142ms/step - loss: 0.4440 - accuracy: 0.7996 - val_loss: 0.4646 - val_accuracy: 0.7608\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.4189 - accuracy: 0.8156 - val_loss: 0.4475 - val_accuracy: 0.7678\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 3s 145ms/step - loss: 0.3966 - accuracy: 0.8281 - val_loss: 0.4333 - val_accuracy: 0.7792\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 3s 151ms/step - loss: 0.3768 - accuracy: 0.8367 - val_loss: 0.4213 - val_accuracy: 0.7878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fccd87d1a30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a classification model:\n",
    "1.The TextVectorization layer transforms strings into vocabulary indices.\n",
    "2.The Embedding layer takes the integer-encoded vocabulary and looks up the \n",
    "embedding vector for each word-index.\n",
    "3.The GlobalAveragePooling1D layer returns a fixed-length output vector for \n",
    "each example by averaging over the sequence dimension.\n",
    "\"\"\"\n",
    "embedding_dim = 16\n",
    "\n",
    "model = Sequential([\n",
    "    vectorize_layer,\n",
    "    Embedding(vocab_size, embedding_dim, name='embedding'),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "tensorboard_callbacks = tf.keras.callbacks.TensorBoard(log_dir='./TensorBoard/Embedding')\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "         validation_data=val_ds,\n",
    "         epochs=15,\n",
    "         callbacks=[tensorboard_callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02f2fb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (TextV  (None, 100)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 16)           160000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a47d555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'more'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "retrieve word embedding and save them to disk\n",
    "weight:(vocab_size, embedding_dimension)\n",
    "\"\"\"\n",
    "weights= model.get_layer('embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e946835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "    if index == 0:\n",
    "        continue    # skip 0, it's padding\n",
    "    vec = weights[index]\n",
    "    out_v.write('\\t'.join([str(x) for x in vec])+\"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "125810de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 10,  25, 736,   5, 275,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(vectorize_layer)\n",
    "model_1.predict(['I have lots of money'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wwt_tf",
   "language": "python",
   "name": "wwt_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
