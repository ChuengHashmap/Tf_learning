{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d547ac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (148242750.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install -q -U \"tensorflow-text==2.11.*\"\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# A dependency of the preprocessing for BERT inputs\n",
    "pip install -q -U \"tensorflow-text==2.11.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c4b09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /home/zhuhou2/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 20:31:42.548089: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n",
      "2023-03-30 20:32:43.554538: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.006153 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
      "2023-03-30 20:33:45.736298: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.005613 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
      "2023-03-30 20:34:48.787539: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.004825 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
      "2023-03-30 20:35:53.873125: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.010371 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
      "2023-03-30 20:37:02.898950: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.005891 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
      "2023-03-30 20:38:20.037620: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.0079 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
      "2023-03-30 20:40:26.567411: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.001126 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
      "2023-03-30 20:42:00.217188: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.006604 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
      "2023-03-30 20:43:33.805184: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.011781 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n",
      "2023-03-30 20:45:06.852225: E tensorflow/tsl/platform/cloud/curl_http_request.cc:610] The transmission  of request 0x55917f373b50 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/datasets%2Fimdb_reviews%2Fplain_text%2F1.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.014 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/zhuhou2/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 20:47:18.829992: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.historyr[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n",
    "    \n",
    "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e482b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      "label:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 20:55:15.424077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-03-30 20:55:15.425391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-03-30 20:55:15.515560: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print('text: ', example.numpy())\n",
    "    print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16d93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wwt_tf",
   "language": "python",
   "name": "wwt_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
